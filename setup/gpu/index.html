<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-setup/gpu">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.1.0">
<title data-rh="true">Cluster GPU Configuration | Rancher Opni</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://opni.io/setup/gpu"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Cluster GPU Configuration | Rancher Opni"><meta data-rh="true" name="description" content="Automatic GPU Operator Configuration"><meta data-rh="true" property="og:description" content="Automatic GPU Operator Configuration"><link data-rh="true" rel="icon" href="/img/favicon.png"><link data-rh="true" rel="canonical" href="https://opni.io/setup/gpu"><link data-rh="true" rel="alternate" href="https://opni.io/setup/gpu" hreflang="en"><link data-rh="true" rel="alternate" href="https://opni.io/setup/gpu" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-56382716-14","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.8ac7f7ba.css">
<link rel="preload" href="/assets/js/runtime~main.ff276d76.js" as="script">
<link rel="preload" href="/assets/js/main.4b3a9623.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="theme.common.skipToMainContent"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/assets/logo-horizontal-opni.svg" alt="logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/assets/logo-horizontal-opni.svg" alt="logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/">v0.10</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/rancher/opni" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar__github">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">More from SUSE</a><ul class="dropdown__menu"><li><a href="https://www.rancher.com" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__rancher">Rancher<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><hr style="margin: 0.3rem 0;"></li><li><a href="https://epinio.io/" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__epinio">Epinio<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://fleet.rancher.io/" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__fleet">Fleet<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://harvesterhci.io" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__harvester">Harvester<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://rancherdesktop.io" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__rd">Rancher Desktop<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><hr style="margin: 0.3rem 0;"></li><li><a href="https://opensource.suse.com" target="_blank" rel="noopener noreferrer" class="dropdown__link navbar__icon navbar__suse">More Projects...<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="searchBox_ZlJk"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Cluster GPU Configuration</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="automatic-gpu-operator-configuration">Automatic GPU Operator Configuration<a class="hash-link" href="#automatic-gpu-operator-configuration" title="Direct link to heading">â€‹</a></h2><p>Opni can utilize GPU acceleration to enable log anomaly detection for workload
and application logs. If you would like Opni to learn from your own workloads,
follow the instructions below to configure your cluster. If GPU acceleration
is not enabled, Opni can still analyze your Control Plane logs using our
pretrained models.</p><p>Opni bundles its own modified version of the Nvidia GPU Operator which is the
recommended way to enable GPU acceleration. It may be possible to install the
upstream GPU Operator via helm chart, but this is not recommended, as it will
likely not work with Opni. Follow the instructions below to enable GPU
acceleration using Opni&#x27;s built-in GPU Operator.</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a class="hash-link" href="#prerequisites" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-node-hardware-requirements">GPU Node Hardware Requirements:<a class="hash-link" href="#gpu-node-hardware-requirements" title="Direct link to heading">â€‹</a></h3><ul><li>1x NVIDIA GPU<ul><li>If not using VGPU, any Quadro or Tesla GPU will work. </li><li>If using VGPU, one of the following GPUs is required:<ul><li>Tesla M6, M10, M60</li><li>Tesla P4, P6, P40, P100</li><li>Tesla V100</li><li>Quadro RTX 6000/8000</li><li>Tesla T4</li><li>NVIDIA A10, A16, A30, A40, A100, RTX A5000/A6000</li></ul></li><li>MIG is not supported when using automatic GPU Operator configuration at this time.</li></ul></li><li>Ubuntu 20.04. No other host OS is supported at this time.</li><li>The GPU node should not have an Nvidia driver or container runtime installed.
The GPU Operator handles installing all the necessary drivers automatically.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="kubernetes-cluster-requirements">Kubernetes Cluster Requirements:<a class="hash-link" href="#kubernetes-cluster-requirements" title="Direct link to heading">â€‹</a></h3><ul><li><p>Vanilla upstream Kubernetes, or one of the following distributions:</p><ul><li>RKE</li><li>K3S &gt;= v1.22.2+k3s1</li><li>RKE2</li><li>Amazon EKS</li><li>Google GKE</li><li>Azure AKS</li></ul></li><li><p>Opni Operator installed</p></li><li><p>Cert-Manager installed </p></li><li><p>NFD installed (see deploy/examples/nfd_aio.yaml in the Opni repo)</p></li></ul><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="install-custom-resources">Install Custom Resources<a class="hash-link" href="#install-custom-resources" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpupolicyadapter">GPUPolicyAdapter<a class="hash-link" href="#gpupolicyadapter" title="Direct link to heading">â€‹</a></h3><p>Creating a GPUPolicyAdapter resource will trigger the GPU Operator to start
configuring the cluster. </p><p>If not using VGPU, the GPUPolicyAdapter resource does not need any customization,
and can be created with an empty spec, as follows:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> opni.io/v1beta1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> GpuPolicyAdapter</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> gpu</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>(note that the empty brackets after <code>spec:</code> are important)</p><p>If using VGPU, please follow the official documentation to build the VGPU driver
image, and create a GPUPolicyAdapter resource with the following spec, filling
in the <code>driver</code> and <code>licenseConfigMap</code> fields:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> opni.io/v1beta1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> GpuPolicyAdapter</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> vgpu</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">images</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token key atrule">driver</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Image name for the VGPU driver</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">vgpu</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token key atrule">licenseConfigMap</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># ConfigMap containing gridd.conf and the client config token</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token key atrule">licenseServerKind</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> nls </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once the GPUPolicyAdapter resource is created, the GPU Operator will begin
configuring the cluster. This takes a few minutes, and the container engine
will be restarted during this process. Once all the pods in the <code>gpu-operator-resources</code>
namespace complete, GPUs will be available for use and the Opni GPU Controller
pod should start.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="provider-specific-notes-and-troubleshooting">Provider-specific Notes and Troubleshooting<a class="hash-link" href="#provider-specific-notes-and-troubleshooting" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="k3s">K3S<a class="hash-link" href="#k3s" title="Direct link to heading">â€‹</a></h3><ul><li>If you are using K3S, you must use v1.22.2+k3s1 or later. This version
introduces automatic detection of Nvidia container runtimes on nodes, and
a large number of bugfixes related to pod lifecycle were added in
upstream Kubernetes for this release. If you are using an earlier version,
you may experience issues where pods become stuck in the &#x27;Terminating&#x27;
state. If this happens, force-deleting the stuck pods should help resolve
the issue.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="rke">RKE<a class="hash-link" href="#rke" title="Direct link to heading">â€‹</a></h3><ul><li><p>RKE uses Docker as its container engine. If you are using RKE, you should
be aware of how the Nvidia runtime interacts with Docker. When the GPU
operator is installed for the first time, it will create a <code>RuntimeClass</code>
object which allows Kubernetes to use the <code>nvidia</code> runtime, which is
configured in the docker engine itself. The RuntimeClass will look similar
to this when using RKE:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> node.k8s.io/v1alpha1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> RuntimeClass</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> nvidia</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">handler</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> docker</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The RuntimeClass <code>name</code> is used in a pod spec to identify the runtime to use.
It is specified using the <code>runtimeClassName</code> field:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> Pod</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token key atrule">runtimeClassName</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> nvidia</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># ...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>When using containerd for example, the <code>handler</code> field in the <code>RuntimeClass</code>
is used to select a specific container runtime by name. However, dockershim
does not support selecting custom container runtimes, meaning the nvidia
container runtime <em>must</em> be set as the default. The GPU Operator will still
utilize a <code>RuntimeClass</code>, but its <code>handler</code> must be set to <code>docker</code> to
work. Otherwise, you may see an error like this:</p><blockquote><p>Failed to create pod sandbox: rpc error: code = Unknown desc = RuntimeHandler &quot;nvidia&quot; not supported</p></blockquote><p>If you encounter this error, check the <code>handler</code> field in the <code>RuntimeClass</code>
and ensure it is set to <code>docker</code>. </p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="vgpu">VGPU<a class="hash-link" href="#vgpu" title="Direct link to heading">â€‹</a></h2><p>If you are using VGPUs, you should be aware of the following:</p><ul><li><p>Nvidia gridd <em>does not</em> run on the virtualization host. Instead, it runs in
guest VMs - when using the GPU Operator, gridd runs inside the nvidia driver
daemonset pod.</p></li><li><p>The VGPU driver must match the driver on the host. When downloading the
driver package from the Nvidia License Portal, you will be presented with
two driver runfiles, for example:</p><ul><li><code>NVIDIA-Linux-x86_64-470.63-vgpu-kvm.run</code> - Installed on the <strong>host</strong></li><li><code>NVIDIA-Linux-x86_64-470.63.01-grid.run</code> - Installed on the <strong>guest</strong> (automatic with GPU operator)</li></ul><p>Ensure the correct drivers are used for the host and guest. </p></li><li><p>CUDA drivers do not need to be installed on the virtualization host (and are not
included by default with the VGPU driver)</p></li><li><p>VGPU mediated device UUIDs are not persistent across reboots. This can cause
libvirt to fail after a reboot if you are running a VM with VGPUs. To fix this:</p><ul><li><p>List instances on the host with <code>virsh list --all</code> (the instance will be shut off)</p></li><li><p>Find the instance that has the VGPU. If you don&#x27;t know which one it is,
use the <code>virsh edit</code> command to view the XML configuration of each instance
and search for <code>mdev</code>.</p></li><li><p>Undefine the instance using <code>virsh undefine</code> and restart libvirtd.</p></li></ul></li><li><p>You might not be able to determine from the host whether a guest VGPU
is licensed. To check license status, you should open a shell to a pod
running with the nvidia container runtime and use <code>nvidia-smi</code> from there.</p></li><li><p>On the virtualization host, you may notice that your physical GPU is bound to
the <code>nvidia</code> driver, even though the <code>nvidia_vgpu_vfio</code> driver is available.
The official docs are ambiguous on this, but your GPU should be bound to
the <code>nvidia</code> driver. The guest VGPU will also be bound to the <code>nvidia</code> driver
once the guest drivers are installed.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="other-notes">Other Notes<a class="hash-link" href="#other-notes" title="Direct link to heading">â€‹</a></h2><ul><li><p>The <code>nvidia.com/gpu</code> resource request behaves counterintuitively. It serves as
a node scheduling hint for pods, and to keep track of which/how many pods are
using GPUs. <code>nvidia.com/gpu</code> a first-class node resource just like cpu and
memory. If a pod makes a request for one, the node it is scheduled on must
have that resource available. The existence of this resource request does
not equate to a pod taking exclusive ownership of the device. In fact, a pod
can use a GPU without requesting an <code>nvidia.com/gpu</code> resource at all, as long
as it has the correct environment variables and <code>runtimeClassName</code> set.
This is how the GPU Operator pods are configured - they do not request GPU
resources by design, rather they are scheduled onto GPU nodes by other means
and set up to use the nvidia container runtime. </p></li><li><p>Regardless of <code>nvidia.com/gpu</code> resource requests or container runtime, GPUs
will <em>only</em> be available if the <code>NVIDIA_VISIBLE_DEVICES</code> and
<code>NVIDIA_DRIVER_CAPABILITIES</code> environment variables are set correctly. They
should be set as follows:</p><ul><li><p><code>NVIDIA_VISIBLE_DEVICES=all</code></p></li><li><p><code>NVIDIA_DRIVER_CAPABILITIES=compute,utility</code></p><p>They can be set either in the pod spec, or in the docker image itself
by using <code>ENV</code> in the Dockerfile.</p></li></ul></li><li><p>If you are not using the GPU operator, but you are using the nvidia device
plugin daemonset by itself, be aware that you must patch the daemonset to
include <code>runtimeClassName: nvidia</code> in its pod template. The GPU operator will
do this automatically, but the daemonset does not have it set by default.</p></li><li><p>The GPU Operator installs the drivers in such a way that they are not
directly visible or usable by the host. As such, tools like <code>nvidia-smi</code> will
not be available, so you will need to exec into a pod running with the nvidia
container runtime to interact with a GPU.</p></li><li><p>A common way to pass a GPU through to a virtual machine is by using the
vfio-pci driver. There are several tutorials online that explain how to set
up vfio-pci. It is important to note that some Nvidia GPUs expose additional
PCI devices (such as an audio or usb controller) in the same IOMMU group
as the GPU device itself. When binding the GPU device to the vfio-pci driver,
ensure that any additional devices belonging to the GPU are bound as well.</p></li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/rancher/opni-docs/edit/main/docs/setup/gpu.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#automatic-gpu-operator-configuration" class="table-of-contents__link toc-highlight">Automatic GPU Operator Configuration</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a><ul><li><a href="#gpu-node-hardware-requirements" class="table-of-contents__link toc-highlight">GPU Node Hardware Requirements:</a></li><li><a href="#kubernetes-cluster-requirements" class="table-of-contents__link toc-highlight">Kubernetes Cluster Requirements:</a></li></ul></li><li><a href="#install-custom-resources" class="table-of-contents__link toc-highlight">Install Custom Resources</a><ul><li><a href="#gpupolicyadapter" class="table-of-contents__link toc-highlight">GPUPolicyAdapter</a></li></ul></li><li><a href="#provider-specific-notes-and-troubleshooting" class="table-of-contents__link toc-highlight">Provider-specific Notes and Troubleshooting</a><ul><li><a href="#k3s" class="table-of-contents__link toc-highlight">K3S</a></li><li><a href="#rke" class="table-of-contents__link toc-highlight">RKE</a></li></ul></li><li><a href="#vgpu" class="table-of-contents__link toc-highlight">VGPU</a></li><li><a href="#other-notes" class="table-of-contents__link toc-highlight">Other Notes</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023 SUSE Rancher. All Rights Reserved.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.ff276d76.js"></script>
<script src="/assets/js/main.4b3a9623.js"></script>
</body>
</html>